#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é«˜çº§åŠŸèƒ½ç¤ºä¾‹
æ¼”ç¤ºPostgreSQLæ•°æ®ç®¡ç†ç³»ç»Ÿçš„é«˜çº§åŠŸèƒ½
åŒ…æ‹¬æ‰¹é‡æ“ä½œã€æ€§èƒ½ä¼˜åŒ–ã€é”™è¯¯å¤„ç†ã€æ•°æ®éªŒè¯ç­‰
"""

import pandas as pd
import numpy as np
import time
import os
import sys
from datetime import datetime, timedelta
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from postgres_manager import PostgreSQLManager
from advanced_manager import AdvancedPostgreSQLManager

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def demonstrate_batch_operations():
    """æ¼”ç¤ºæ‰¹é‡æ“ä½œåŠŸèƒ½"""
    print("=" * 60)
    print("1. æ‰¹é‡æ“ä½œåŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)
    
    print("\n1.1 å‡†å¤‡æ‰¹é‡æ•°æ®æº")
    print("-" * 40)
    
    # å‡†å¤‡å¤šç§æ•°æ®æº
    data_sources = []
    table_names = []
    
    # 1. DataFrameæ•°æ®æº
    df1 = pd.DataFrame({
        '000001.SZ': np.random.randn(50),
        '000002.SZ': np.random.randn(50)
    }, index=pd.date_range('2023-01-01', periods=50))
    data_sources.append(df1)
    table_names.append("batch_df1")
    
    # 2. å­—å…¸æ•°æ®æº
    dict1 = {
        'datetime': pd.date_range('2023-02-01', periods=30).strftime('%Y-%m-%d').tolist(),
        '600000.SH': np.random.uniform(10, 50, 30).tolist(),
        '600036.SH': np.random.uniform(20, 60, 30).tolist()
    }
    data_sources.append(dict1)
    table_names.append("batch_dict1")
    
    # 3. æ›´å¤šDataFrame
    df2 = pd.DataFrame({
        '000858.SZ': np.random.randn(40),
        '002415.SZ': np.random.randn(40)
    }, index=pd.date_range('2023-03-01', periods=40))
    data_sources.append(df2)
    table_names.append("batch_df2")
    
    print(f"âœ“ å‡†å¤‡äº† {len(data_sources)} ä¸ªæ•°æ®æº")
    
    print("\n1.2 æ‰§è¡Œæ‰¹é‡å¯¼å…¥")
    print("-" * 40)
    
    with AdvancedPostgreSQLManager() as db:
        start_time = time.time()
        
        # æ‰§è¡Œæ‰¹é‡å¯¼å…¥
        results = db.batch_insert_data(
            data_sources=data_sources,
            table_names=table_names,
            overwrite=True
        )
        
        end_time = time.time()
        
        print(f"âœ“ æ‰¹é‡å¯¼å…¥å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f} ç§’")
        print("å¯¼å…¥ç»“æœ:")
        
        for table_name, success in results.items():
            if success:
                info = db.get_table_info(table_name)
                print(f"  âœ“ {table_name}: {info['row_count']} è¡Œ, {info['column_count']} åˆ—")
            else:
                print(f"  âœ— {table_name}: å¯¼å…¥å¤±è´¥")
    
    print("\n1.3 æ‰¹é‡æŸ¥è¯¢æ“ä½œ")
    print("-" * 40)
    
    with AdvancedPostgreSQLManager() as db:
        # æ‰¹é‡æŸ¥è¯¢å¤šä¸ªè¡¨
        successful_tables = [name for name, success in results.items() if success]
        
        start_time = time.time()
        
        query_results = {}
        for table_name in successful_tables:
            data = db.query_data(table_name, limit=10)
            if data is not None:
                query_results[table_name] = data
        
        end_time = time.time()
        
        print(f"âœ“ æ‰¹é‡æŸ¥è¯¢å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f} ç§’")
        print(f"âœ“ æˆåŠŸæŸ¥è¯¢ {len(query_results)} ä¸ªè¡¨")
        
        for table_name, data in query_results.items():
            print(f"  {table_name}: {data.shape}")

def demonstrate_performance_optimization():
    """æ¼”ç¤ºæ€§èƒ½ä¼˜åŒ–åŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("2. æ€§èƒ½ä¼˜åŒ–åŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)
    
    print("\n2.1 å¤§æ•°æ®é‡å¤„ç†æµ‹è¯•")
    print("-" * 40)
    
    # åˆ›å»ºå¤§æ•°æ®é‡æµ‹è¯•æ•°æ®
    large_data_sizes = [1000, 5000, 10000]
    stock_codes = ['000001.SZ', '000002.SZ', '600000.SH', '600036.SH', '000858.SZ']
    
    with PostgreSQLManager() as db:
        performance_results = {}
        
        for size in large_data_sizes:
            print(f"\næµ‹è¯•æ•°æ®é‡: {size} è¡Œ")
            
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            test_data = pd.DataFrame(
                np.random.randn(size, len(stock_codes)),
                columns=stock_codes,
                index=pd.date_range('2020-01-01', periods=size, freq='D')
            )
            
            table_name = f"perf_test_{size}"
            
            # æµ‹è¯•åˆ›å»ºè¡¨çš„æ€§èƒ½
            start_time = time.time()
            success = db.create_table(table_name, test_data, overwrite=True)
            create_time = time.time() - start_time
            
            if success:
                # æµ‹è¯•æŸ¥è¯¢æ€§èƒ½
                start_time = time.time()
                query_result = db.query_data(table_name, limit=1000)
                query_time = time.time() - start_time
                
                # æµ‹è¯•æ’å…¥æ€§èƒ½
                new_data = pd.DataFrame(
                    np.random.randn(100, len(stock_codes)),
                    columns=stock_codes,
                    index=pd.date_range('2025-01-01', periods=100, freq='D')
                )
                
                start_time = time.time()
                insert_success = db.insert_data(table_name, new_data)
                insert_time = time.time() - start_time
                
                performance_results[size] = {
                    'create_time': create_time,
                    'query_time': query_time,
                    'insert_time': insert_time,
                    'success': True
                }
                
                print(f"  âœ“ åˆ›å»º: {create_time:.3f}s, æŸ¥è¯¢: {query_time:.3f}s, æ’å…¥: {insert_time:.3f}s")
            else:
                performance_results[size] = {'success': False}
                print(f"  âœ— åˆ›å»ºè¡¨å¤±è´¥")
        
        print("\n2.2 æ€§èƒ½ç»Ÿè®¡åˆ†æ")
        print("-" * 40)
        
        if performance_results:
            perf_df = pd.DataFrame({
                size: results for size, results in performance_results.items() 
                if results.get('success', False)
            }).T
            
            if not perf_df.empty:
                print("âœ“ æ€§èƒ½æµ‹è¯•ç»“æœ:")
                print(perf_df[['create_time', 'query_time', 'insert_time']].round(3))
                
                # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
                print("\nâœ“ æ€§èƒ½æŒ‡æ ‡åˆ†æ:")
                print(f"  å¹³å‡åˆ›å»ºæ—¶é—´: {perf_df['create_time'].mean():.3f}s")
                print(f"  å¹³å‡æŸ¥è¯¢æ—¶é—´: {perf_df['query_time'].mean():.3f}s")
                print(f"  å¹³å‡æ’å…¥æ—¶é—´: {perf_df['insert_time'].mean():.3f}s")

def demonstrate_error_handling():
    """æ¼”ç¤ºé”™è¯¯å¤„ç†åŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("3. é”™è¯¯å¤„ç†åŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)
    
    with PostgreSQLManager() as db:
        print("\n3.1 æ•°æ®ç±»å‹é”™è¯¯å¤„ç†")
        print("-" * 40)
        
        # æµ‹è¯•ä¸å…¼å®¹çš„æ•°æ®ç±»å‹
        try:
            invalid_data = {
                'datetime': ['2023-01-01', '2023-01-02'],
                'mixed_col': ['text', 123]  # æ··åˆç±»å‹
            }
            
            success = db.create_table("error_test_mixed", invalid_data, overwrite=True)
            if success:
                print("âœ“ æ··åˆç±»å‹æ•°æ®å¤„ç†æˆåŠŸï¼ˆç³»ç»Ÿè‡ªåŠ¨è½¬æ¢ï¼‰")
                result = db.query_data("error_test_mixed")
                print(f"  æ•°æ®ç±»å‹: {result.dtypes.to_dict()}")
            else:
                print("âœ— æ··åˆç±»å‹æ•°æ®å¤„ç†å¤±è´¥")
                
        except Exception as e:
            print(f"âœ— æ•°æ®ç±»å‹é”™è¯¯: {str(e)}")
        
        print("\n3.2 ç©ºæ•°æ®å¤„ç†")
        print("-" * 40)
        
        # æµ‹è¯•ç©ºæ•°æ®
        try:
            empty_data = pd.DataFrame()
            success = db.create_table("error_test_empty", empty_data, overwrite=True)
            if success:
                print("âœ“ ç©ºæ•°æ®å¤„ç†æˆåŠŸ")
            else:
                print("âœ— ç©ºæ•°æ®å¤„ç†å¤±è´¥ï¼ˆé¢„æœŸè¡Œä¸ºï¼‰")
        except Exception as e:
            print(f"âœ“ ç©ºæ•°æ®é”™è¯¯å¤„ç†: {str(e)}")
        
        print("\n3.3 é‡å¤è¡¨åå¤„ç†")
        print("-" * 40)
        
        # æµ‹è¯•é‡å¤è¡¨å
        try:
            test_data = pd.DataFrame({'A': [1, 2, 3]}, index=pd.date_range('2023-01-01', periods=3))
            
            # ç¬¬ä¸€æ¬¡åˆ›å»º
            success1 = db.create_table("duplicate_test", test_data, overwrite=False)
            print(f"âœ“ é¦–æ¬¡åˆ›å»ºè¡¨: {success1}")
            
            # ç¬¬äºŒæ¬¡åˆ›å»ºï¼ˆä¸è¦†ç›–ï¼‰
            success2 = db.create_table("duplicate_test", test_data, overwrite=False)
            print(f"âœ“ é‡å¤åˆ›å»ºï¼ˆä¸è¦†ç›–ï¼‰: {success2}")
            
            # ç¬¬ä¸‰æ¬¡åˆ›å»ºï¼ˆè¦†ç›–ï¼‰
            success3 = db.create_table("duplicate_test", test_data, overwrite=True)
            print(f"âœ“ é‡å¤åˆ›å»ºï¼ˆè¦†ç›–ï¼‰: {success3}")
            
        except Exception as e:
            print(f"âœ— é‡å¤è¡¨åå¤„ç†é”™è¯¯: {str(e)}")
        
        print("\n3.4 æ— æ•ˆæŸ¥è¯¢å¤„ç†")
        print("-" * 40)
        
        # æµ‹è¯•æŸ¥è¯¢ä¸å­˜åœ¨çš„è¡¨
        try:
            result = db.query_data("nonexistent_table")
            if result is None:
                print("âœ“ ä¸å­˜åœ¨è¡¨çš„æŸ¥è¯¢æ­£ç¡®è¿”å›None")
            else:
                print("âœ— ä¸å­˜åœ¨è¡¨çš„æŸ¥è¯¢è¿”å›äº†æ•°æ®")
        except Exception as e:
            print(f"âœ“ æ— æ•ˆæŸ¥è¯¢é”™è¯¯å¤„ç†: {str(e)}")
        
        # æµ‹è¯•æ— æ•ˆæ—¥æœŸèŒƒå›´
        try:
            if db.table_exists("duplicate_test"):
                result = db.query_data("duplicate_test", start_date="2025-01-01", end_date="2024-01-01")
                if result is None or result.empty:
                    print("âœ“ æ— æ•ˆæ—¥æœŸèŒƒå›´æŸ¥è¯¢æ­£ç¡®å¤„ç†")
                else:
                    print(f"âœ“ æ— æ•ˆæ—¥æœŸèŒƒå›´æŸ¥è¯¢è¿”å›: {result.shape}")
        except Exception as e:
            print(f"âœ“ æ— æ•ˆæ—¥æœŸèŒƒå›´é”™è¯¯å¤„ç†: {str(e)}")

def demonstrate_data_validation():
    """æ¼”ç¤ºæ•°æ®éªŒè¯åŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("4. æ•°æ®éªŒè¯åŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)
    
    print("\n4.1 æ•°æ®å®Œæ•´æ€§éªŒè¯")
    print("-" * 40)
    
    with PostgreSQLManager() as db:
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        validation_data = pd.DataFrame({
            '000001.SZ': [10.5, 11.2, np.nan, 12.8, 13.1],  # åŒ…å«NaN
            '000002.SZ': [20.1, 21.5, 22.3, 23.0, 24.2]
        }, index=pd.date_range('2023-01-01', periods=5))
        
        success = db.create_table("validation_test", validation_data, overwrite=True)
        
        if success:
            # æŸ¥è¯¢æ•°æ®å¹¶éªŒè¯
            result = db.query_data("validation_test")
            
            print(f"âœ“ æ•°æ®å½¢çŠ¶: {result.shape}")
            print(f"âœ“ ç¼ºå¤±å€¼ç»Ÿè®¡:")
            print(result.isnull().sum())
            
            # æ•°æ®ç±»å‹éªŒè¯
            print(f"âœ“ æ•°æ®ç±»å‹:")
            print(result.dtypes)
            
            # æ•°å€¼èŒƒå›´éªŒè¯
            numeric_cols = result.select_dtypes(include=[np.number]).columns
            print(f"âœ“ æ•°å€¼èŒƒå›´:")
            for col in numeric_cols:
                print(f"  {col}: [{result[col].min():.2f}, {result[col].max():.2f}]")
    
    print("\n4.2 æ—¶é—´åºåˆ—éªŒè¯")
    print("-" * 40)
    
    with PostgreSQLManager() as db:
        if db.table_exists("validation_test"):
            result = db.query_data("validation_test")
            
            # æ—¶é—´ç´¢å¼•éªŒè¯
            if 'datetime' in result.columns:
                datetime_col = pd.to_datetime(result['datetime'])
                
                print(f"âœ“ æ—¶é—´èŒƒå›´: {datetime_col.min()} åˆ° {datetime_col.max()}")
                print(f"âœ“ æ—¶é—´ç‚¹æ•°é‡: {len(datetime_col)}")
                
                # æ£€æŸ¥æ—¶é—´åºåˆ—çš„è¿ç»­æ€§
                time_diffs = datetime_col.diff().dropna()
                if len(time_diffs.unique()) == 1:
                    print(f"âœ“ æ—¶é—´åºåˆ—è¿ç»­ï¼Œé—´éš”: {time_diffs.iloc[0]}")
                else:
                    print(f"âœ“ æ—¶é—´åºåˆ—ä¸è§„åˆ™ï¼Œé—´éš”èŒƒå›´: {time_diffs.min()} åˆ° {time_diffs.max()}")
    
    print("\n4.3 æ•°æ®è´¨é‡è¯„ä¼°")
    print("-" * 40)
    
    with PostgreSQLManager() as db:
        if db.table_exists("validation_test"):
            result = db.query_data("validation_test")
            
            # æ•°æ®è´¨é‡æŒ‡æ ‡
            total_cells = result.shape[0] * result.shape[1]
            missing_cells = result.isnull().sum().sum()
            completeness = (total_cells - missing_cells) / total_cells
            
            print(f"âœ“ æ•°æ®å®Œæ•´æ€§: {completeness:.2%}")
            
            # æ•°å€¼åˆ—çš„ç»Ÿè®¡ç‰¹å¾
            numeric_cols = result.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                stats = result[numeric_cols].describe()
                print(f"âœ“ æ•°å€¼ç»Ÿè®¡ç‰¹å¾:")
                print(stats.round(3))
                
                # å¼‚å¸¸å€¼æ£€æµ‹ï¼ˆç®€å•çš„3Ïƒè§„åˆ™ï¼‰
                for col in numeric_cols:
                    mean_val = result[col].mean()
                    std_val = result[col].std()
                    outliers = result[(result[col] < mean_val - 3*std_val) | 
                                    (result[col] > mean_val + 3*std_val)]
                    if len(outliers) > 0:
                        print(f"  {col}: å‘ç° {len(outliers)} ä¸ªå¼‚å¸¸å€¼")
                    else:
                        print(f"  {col}: æ— å¼‚å¸¸å€¼")

def demonstrate_advanced_queries():
    """æ¼”ç¤ºé«˜çº§æŸ¥è¯¢åŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("5. é«˜çº§æŸ¥è¯¢åŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)
    
    with AdvancedPostgreSQLManager() as db:
        print("\n5.1 å‡†å¤‡æŸ¥è¯¢æµ‹è¯•æ•°æ®")
        print("-" * 40)
        
        # åˆ›å»ºå¤šä¸ªç›¸å…³è¡¨
        stock_codes = ['000001.SZ', '000002.SZ', '600000.SH']
        dates = pd.date_range('2023-01-01', periods=100, freq='D')
        
        # ä»·æ ¼è¡¨
        price_data = pd.DataFrame(
            np.random.uniform(10, 100, (len(dates), len(stock_codes))),
            index=dates,
            columns=stock_codes
        )
        db.create_table("adv_query_prices", price_data, overwrite=True)
        
        # æˆäº¤é‡è¡¨
        volume_data = pd.DataFrame(
            np.random.uniform(1000000, 10000000, (len(dates), len(stock_codes))),
            index=dates,
            columns=stock_codes
        )
        db.create_table("adv_query_volume", volume_data, overwrite=True)
        
        print("âœ“ æŸ¥è¯¢æµ‹è¯•æ•°æ®å‡†å¤‡å®Œæˆ")
        
        print("\n5.2 æ¡ä»¶æŸ¥è¯¢æµ‹è¯•")
        print("-" * 40)
        
        # æŒ‰æ—¥æœŸèŒƒå›´æŸ¥è¯¢
        date_result = db.query_data(
            "adv_query_prices",
            start_date="2023-02-01",
            end_date="2023-02-28"
        )
        print(f"âœ“ æ—¥æœŸèŒƒå›´æŸ¥è¯¢: {date_result.shape}")
        
        # é™åˆ¶ç»“æœæ•°é‡
        limit_result = db.query_data("adv_query_prices", limit=10)
        print(f"âœ“ é™åˆ¶æ•°é‡æŸ¥è¯¢: {limit_result.shape}")
        
        # ç»„åˆæ¡ä»¶æŸ¥è¯¢
        combo_result = db.query_data(
            "adv_query_prices",
            start_date="2023-03-01",
            end_date="2023-03-31",
            limit=20
        )
        print(f"âœ“ ç»„åˆæ¡ä»¶æŸ¥è¯¢: {combo_result.shape}")
        
        print("\n5.3 å¤šè¡¨è”åˆæŸ¥è¯¢")
        print("-" * 40)
        
        # å¤šå› å­æŸ¥è¯¢
        multifactor_result = db.query_data_multifactor(
            table_names=["adv_query_prices", "adv_query_volume"],
            stock_codes=["000001.SZ", "000002.SZ"],
            start_date="2023-01-01",
            end_date="2023-01-31"
        )
        
        if multifactor_result is not None:
            print(f"âœ“ å¤šå› å­æŸ¥è¯¢: {multifactor_result.shape}")
            print("âœ“ æŸ¥è¯¢åˆ—:", multifactor_result.columns.tolist())
        else:
            print("âœ— å¤šå› å­æŸ¥è¯¢å¤±è´¥")
        
        print("\n5.4 èšåˆæŸ¥è¯¢åŠŸèƒ½")
        print("-" * 40)
        
        # è·å–æ•°æ®è¿›è¡Œèšåˆåˆ†æ
        monthly_data = db.query_data(
            "adv_query_prices",
            start_date="2023-01-01",
            end_date="2023-12-31"
        )
        
        if monthly_data is not None:
            # è½¬æ¢datetimeåˆ—
            monthly_data['datetime'] = pd.to_datetime(monthly_data['datetime'])
            monthly_data.set_index('datetime', inplace=True)
            
            # æœˆåº¦èšåˆ
            monthly_avg = monthly_data.resample('M').mean()
            print(f"âœ“ æœˆåº¦å¹³å‡ä»·æ ¼: {monthly_avg.shape}")
            print("å‰3ä¸ªæœˆæ•°æ®:")
            print(monthly_avg.head(3).round(2))
            
            # å­£åº¦èšåˆ
            quarterly_avg = monthly_data.resample('Q').mean()
            print(f"âœ“ å­£åº¦å¹³å‡ä»·æ ¼: {quarterly_avg.shape}")

def demonstrate_backup_restore():
    """æ¼”ç¤ºå¤‡ä»½æ¢å¤åŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("6. å¤‡ä»½æ¢å¤åŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)
    
    print("\n6.1 æ•°æ®å¯¼å‡ºåŠŸèƒ½")
    print("-" * 40)
    
    with PostgreSQLManager() as db:
        # ç¡®ä¿æœ‰æ•°æ®å¯ä»¥å¯¼å‡º
        if db.table_exists("validation_test"):
            # å¯¼å‡ºåˆ°CSV
            export_path = "backup_test_export.csv"
            success = db.export_to_csv("validation_test", export_path)
            
            if success and os.path.exists(export_path):
                print(f"âœ“ æ•°æ®å¯¼å‡ºæˆåŠŸ: {export_path}")
                
                # éªŒè¯å¯¼å‡ºæ–‡ä»¶
                exported_data = pd.read_csv(export_path)
                print(f"âœ“ å¯¼å‡ºæ•°æ®éªŒè¯: {exported_data.shape}")
                
                # æ¸…ç†å¯¼å‡ºæ–‡ä»¶
                os.remove(export_path)
                print("âœ“ æ¸…ç†å¯¼å‡ºæ–‡ä»¶")
            else:
                print("âœ— æ•°æ®å¯¼å‡ºå¤±è´¥")
        
        print("\n6.2 è¡¨ç»“æ„ä¿¡æ¯")
        print("-" * 40)
        
        # è·å–è¡¨ä¿¡æ¯
        tables = db.list_tables()
        test_tables = [t for t in tables if 'test' in t or 'batch' in t or 'adv_query' in t]
        
        print(f"âœ“ å‘ç°æµ‹è¯•è¡¨: {len(test_tables)} ä¸ª")
        
        for table in test_tables[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            info = db.get_table_info(table)
            print(f"  {table}: {info['row_count']} è¡Œ, {info['column_count']} åˆ—")

def cleanup_advanced_examples():
    """æ¸…ç†é«˜çº§åŠŸèƒ½ç¤ºä¾‹æ•°æ®"""
    print("\n" + "=" * 60)
    print("7. æ¸…ç†é«˜çº§åŠŸèƒ½ç¤ºä¾‹æ•°æ®")
    print("=" * 60)
    
    with PostgreSQLManager() as db:
        tables = db.list_tables()
        cleanup_tables = [t for t in tables if any(prefix in t for prefix in [
            'batch_', 'perf_test_', 'error_test_', 'validation_test', 
            'duplicate_test', 'adv_query_'
        ])]
        
        print(f"å‘ç° {len(cleanup_tables)} ä¸ªéœ€è¦æ¸…ç†çš„è¡¨")
        
        for table in cleanup_tables:
            success = db.drop_table(table)
            if success:
                print(f"âœ“ åˆ é™¤è¡¨: {table}")
            else:
                print(f"âœ— åˆ é™¤å¤±è´¥: {table}")

def main():
    """ä¸»å‡½æ•°"""
    print("PostgreSQLæ•°æ®ç®¡ç†ç³»ç»Ÿ - é«˜çº§åŠŸèƒ½ç¤ºä¾‹")
    print("=" * 80)
    
    try:
        # 1. æ‰¹é‡æ“ä½œæ¼”ç¤º
        demonstrate_batch_operations()
        
        # 2. æ€§èƒ½ä¼˜åŒ–æ¼”ç¤º
        demonstrate_performance_optimization()
        
        # 3. é”™è¯¯å¤„ç†æ¼”ç¤º
        demonstrate_error_handling()
        
        # 4. æ•°æ®éªŒè¯æ¼”ç¤º
        demonstrate_data_validation()
        
        # 5. é«˜çº§æŸ¥è¯¢æ¼”ç¤º
        demonstrate_advanced_queries()
        
        # 6. å¤‡ä»½æ¢å¤æ¼”ç¤º
        demonstrate_backup_restore()
        
        # 7. æ¸…ç†ç¤ºä¾‹æ•°æ®
        cleanup_advanced_examples()
        
        print("\n" + "=" * 80)
        print("âœ… é«˜çº§åŠŸèƒ½ç¤ºä¾‹æ¼”ç¤ºå®Œæˆï¼")
        print("=" * 80)
        
        print("\nğŸ“‹ é«˜çº§åŠŸèƒ½æ€»ç»“:")
        print("1. âœ“ æ‰¹é‡æ“ä½œï¼šå¤šæ•°æ®æºæ‰¹é‡å¯¼å…¥å’ŒæŸ¥è¯¢")
        print("2. âœ“ æ€§èƒ½ä¼˜åŒ–ï¼šå¤§æ•°æ®é‡å¤„ç†æ€§èƒ½æµ‹è¯•")
        print("3. âœ“ é”™è¯¯å¤„ç†ï¼šå„ç§å¼‚å¸¸æƒ…å†µçš„ä¼˜é›…å¤„ç†")
        print("4. âœ“ æ•°æ®éªŒè¯ï¼šå®Œæ•´æ€§ã€è´¨é‡å’Œå¼‚å¸¸å€¼æ£€æµ‹")
        print("5. âœ“ é«˜çº§æŸ¥è¯¢ï¼šæ¡ä»¶æŸ¥è¯¢ã€å¤šè¡¨è”åˆã€èšåˆåˆ†æ")
        print("6. âœ“ å¤‡ä»½æ¢å¤ï¼šæ•°æ®å¯¼å‡ºå’Œè¡¨ç»“æ„ç®¡ç†")
        print("7. âœ“ èµ„æºç®¡ç†ï¼šè‡ªåŠ¨æ¸…ç†å’Œå†…å­˜ä¼˜åŒ–")
        
        print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
        print("- å¤§æ•°æ®é‡æ“ä½œæ—¶å»ºè®®ä½¿ç”¨æ‰¹é‡åŠŸèƒ½")
        print("- ç”Ÿäº§ç¯å¢ƒä¸­å¯ç”¨å®Œæ•´çš„é”™è¯¯å¤„ç†")
        print("- å®šæœŸè¿›è¡Œæ•°æ®è´¨é‡éªŒè¯")
        print("- åˆç†ä½¿ç”¨æŸ¥è¯¢æ¡ä»¶ä»¥æé«˜æ€§èƒ½")
        
    except Exception as e:
        print(f"\nâŒ é«˜çº§åŠŸèƒ½æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()