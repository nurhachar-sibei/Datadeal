# PostgreSQLæ•°æ®ç®¡ç†ç³»ç»Ÿ

ä¸€ä¸ªä¸“ä¸ºé‡‘èæ—¶é—´åºåˆ—æ•°æ®è®¾è®¡çš„é«˜æ€§èƒ½PostgreSQLæ•°æ®ç®¡ç†ç³»ç»Ÿï¼Œæä¾›å®Œæ•´çš„æ•°æ®å¯¼å…¥ã€æŸ¥è¯¢ã€åˆ†æå’Œç®¡ç†åŠŸèƒ½ã€‚

## ğŸš€ é¡¹ç›®æ¦‚è¿°

æœ¬ç³»ç»Ÿä¸“é—¨é’ˆå¯¹é‡‘èæ•°æ®åˆ†æåœºæ™¯è®¾è®¡ï¼Œæ”¯æŒè‚¡ç¥¨ä»·æ ¼ã€åŸºæœ¬é¢æŒ‡æ ‡ã€æŠ€æœ¯æŒ‡æ ‡ç­‰å¤šç§ç±»å‹çš„æ—¶é—´åºåˆ—æ•°æ®ç®¡ç†ã€‚ç³»ç»Ÿé‡‡ç”¨PostgreSQLä½œä¸ºåç«¯æ•°æ®åº“ï¼Œæä¾›é«˜æ•ˆçš„æ•°æ®å­˜å‚¨å’ŒæŸ¥è¯¢èƒ½åŠ›ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

### æ•°æ®ç®¡ç†åŠŸèƒ½

- **æ™ºèƒ½è¡¨æ ¼åˆ›å»º**: è‡ªåŠ¨ä»CSVæ–‡ä»¶æˆ–DataFrameåˆ›å»ºä¼˜åŒ–çš„æ•°æ®åº“è¡¨
- **å¤šæºæ•°æ®æ”¯æŒ**: æ”¯æŒCSVæ–‡ä»¶ã€pandas DataFrameã€å­—å…¸ç­‰å¤šç§æ•°æ®æº
- **æ‰¹é‡æ•°æ®å¯¼å…¥**: æ”¯æŒå•æ–‡ä»¶å’Œå¤šæ–‡ä»¶æ‰¹é‡å¯¼å…¥
- **å¢é‡æ•°æ®æ›´æ–°**: æ™ºèƒ½å¤„ç†é‡å¤æ•°æ®ï¼Œæ”¯æŒæ•°æ®åˆå¹¶å’Œæ›´æ–°
- **çµæ´»æ•°æ®æŸ¥è¯¢**: æ”¯æŒæ¡ä»¶æŸ¥è¯¢ã€æ—¶é—´åˆ‡ç‰‡ã€åˆ—ç­›é€‰ç­‰å¤šç§æŸ¥è¯¢æ–¹å¼
- **å¤šå› å­æŸ¥è¯¢**: æ”¯æŒè·¨è¡¨å¤šå› å­æ•°æ®è”åˆæŸ¥è¯¢å’Œåˆ†æ
- **æ•°æ®å¯¼å‡º**: æ”¯æŒå¤šç§æ ¼å¼çš„æ•°æ®å¯¼å‡ºåŠŸèƒ½

### é«˜çº§åŠŸèƒ½

- **æ—¶é—´åºåˆ—ä¼˜åŒ–**: ä¸“ä¸ºæ—¶é—´åºåˆ—æ•°æ®è®¾è®¡çš„ç´¢å¼•å’ŒæŸ¥è¯¢ä¼˜åŒ–
- **æ•°æ®è´¨é‡éªŒè¯**: è‡ªåŠ¨æ£€æŸ¥æ•°æ®å®Œæ•´æ€§å’Œä¸€è‡´æ€§
- **æ€§èƒ½ç›‘æ§**: è¯¦ç»†çš„æ“ä½œæ—¥å¿—å’Œæ€§èƒ½ç»Ÿè®¡
- **é”™è¯¯æ¢å¤**: å®Œå–„çš„äº‹åŠ¡ç®¡ç†å’Œé”™è¯¯å¤„ç†æœºåˆ¶
- **æ‰¹é‡æ“ä½œ**: é«˜æ•ˆçš„æ‰¹é‡æ•°æ®å¤„ç†èƒ½åŠ›

## ğŸ“Š æ”¯æŒçš„æ•°æ®æ ¼å¼

### è¾“å…¥æ•°æ®æ ¼å¼

ç³»ç»Ÿæ”¯æŒä»¥ä¸‹ç±»å‹çš„æ•°æ®æºï¼š

#### 1. CSVæ–‡ä»¶æ•°æ®æº

æ”¯æŒæ ‡å‡†çš„CSVæ—¶é—´åºåˆ—æ•°æ®æ–‡ä»¶ï¼š

```csv
datetime,000001.SZ,000002.SZ,000858.SZ,002415.SZ,002594.SZ,600000.SH,600036.SH,600519.SH
2020-01-01,0.907,2.534,0.578,2.116,4.195,1.158,3.295,3.179
2020-01-02,1.116,4.664,4.135,3.609,3.188,0.779,3.237,1.396
```

#### 2. pandas DataFrameæ•°æ®æº

ç›´æ¥æ”¯æŒpandas DataFrameå¯¹è±¡ï¼š

```python
import pandas as pd
import numpy as np

# åˆ›å»ºDataFrame
dates = pd.date_range('2020-01-01', periods=100, freq='D')
df = pd.DataFrame({
    '000001.SZ': np.random.randn(100),
    '000002.SZ': np.random.randn(100),
    '600000.SH': np.random.randn(100)
}, index=dates)

# ç›´æ¥ä½¿ç”¨DataFrameåˆ›å»ºè¡¨
db.create_table("my_table", df)
```

#### 3. å­—å…¸æ•°æ®æº

æ”¯æŒå­—å…¸æ ¼å¼çš„æ•°æ®ï¼š

```python
# å­—å…¸æ•°æ®æº
data_dict = {
    'datetime': ['2020-01-01', '2020-01-02', '2020-01-03'],
    '000001.SZ': [1.23, 1.45, 1.67],
    '000002.SZ': [2.34, 2.56, 2.78],
    '600000.SH': [3.45, 3.67, 3.89]
}

# ä½¿ç”¨å­—å…¸åˆ›å»ºè¡¨
db.create_table("dict_table", data_dict)
```

### æ•°æ®ç±»å‹æ”¯æŒ

#### åŸºæœ¬é¢æ•°æ® (Fundamental Data)

- **PBæ¯”ç‡**: å¸‚å‡€ç‡æ•°æ®
- **PEæ¯”ç‡**: å¸‚ç›ˆç‡æ•°æ®
- **ROE**: å‡€èµ„äº§æ”¶ç›Šç‡æ•°æ®
- **è¥æ”¶å¢é•¿ç‡**: è¥æ”¶å¢é•¿ç‡æ•°æ®

#### ä»·æ ¼æ•°æ® (Price Data)

- **å¼€ç›˜ä»·**: è‚¡ç¥¨å¼€ç›˜ä»·æ ¼
- **æ”¶ç›˜ä»·**: è‚¡ç¥¨æ”¶ç›˜ä»·æ ¼
- **æœ€é«˜ä»·**: è‚¡ç¥¨æœ€é«˜ä»·æ ¼
- **æœ€ä½ä»·**: è‚¡ç¥¨æœ€ä½ä»·æ ¼
- **æˆäº¤é‡**: è‚¡ç¥¨æˆäº¤é‡æ•°æ®

#### æŠ€æœ¯æŒ‡æ ‡æ•°æ® (Technical Data)

- **RSI**: ç›¸å¯¹å¼ºå¼±æŒ‡æ ‡
- **MACD**: æŒ‡æ•°å¹³æ»‘ç§»åŠ¨å¹³å‡çº¿
- **å¸ƒæ—å¸¦å®½åº¦**: å¸ƒæ—å¸¦æŠ€æœ¯æŒ‡æ ‡
- **ç§»åŠ¨å¹³å‡æ¯”ç‡**: ç§»åŠ¨å¹³å‡çº¿æ¯”ç‡

### æ•°æ®åº“è¡¨ç»“æ„

ç³»ç»Ÿè‡ªåŠ¨åˆ›å»ºçš„è¡¨ç»“æ„å¦‚ä¸‹ï¼š

```sql
CREATE TABLE table_name (
    datetime TIMESTAMP PRIMARY KEY,
    "000001.SZ" DOUBLE PRECISION,
    "000002.SZ" DOUBLE PRECISION,
    "000858.SZ" DOUBLE PRECISION,
    -- ... å…¶ä»–è‚¡ç¥¨ä»£ç åˆ—
);

-- è‡ªåŠ¨åˆ›å»ºæ—¶é—´ç´¢å¼•
CREATE INDEX idx_table_name_datetime ON table_name (datetime);
```

### è¾“å‡ºæ•°æ®æ ¼å¼

#### æŸ¥è¯¢ç»“æœDataFrame

```python
# æ ‡å‡†æŸ¥è¯¢è¾“å‡º
                000001.SZ  000002.SZ  000858.SZ  002415.SZ
datetime                                          
2020-01-01      0.907444   2.533771   0.578473   2.115682
2020-01-02      1.116457   4.664031   4.134741   3.608640
2020-01-03      1.064950   0.674015   2.350563   4.018990
```

#### ç»Ÿè®¡ä¿¡æ¯è¾“å‡º

```python
{
    'row_count': 1043,
    'column_count': 15,
    'date_range': {
        'start': '2020-01-01',
        'end': '2022-12-30'
    },
    'missing_values': 0,
    'data_types': {
        'datetime': 'datetime64[ns]',
        '000001.SZ': 'float64',
        '000002.SZ': 'float64'
    }
}
```

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
Datadeal/
â”œâ”€â”€ postgres_manager.py      # æ ¸å¿ƒæ•°æ®åº“ç®¡ç†ç±»
â”œâ”€â”€ advanced_manager.py      # é«˜çº§åŠŸèƒ½æ‰©å±•ç±»
â”œâ”€â”€ README.md              # é¡¹ç›®æ–‡æ¡£
â”œâ”€â”€ easy_test.ipynb         # ç®€å•çš„æµ‹è¯•æ–‡ä»¶ï¼ˆå¤æ‚çš„åœ¨æµ‹è¯•æ–‡ä»¶å’Œæ¡ˆä¾‹æ–‡ä»¶-è™½ç„¶å¯èƒ½æ²¡å•¥ç”¨ï¼‰
â”œâ”€â”€ test_file/             # å„ç§æµ‹è¯•æ–‡ä»¶ç›®å½•
â”œâ”€â”€ sample_data/           # æ ·æœ¬æ•°æ®ç›®å½• (13ä¸ªCSVæ–‡ä»¶)
â”‚   â”œâ”€â”€ Fundamental_PB_Ratio.csv      # å¸‚å‡€ç‡æ•°æ®
â”‚   â”œâ”€â”€ Fundamental_PE_Ratio.csv      # å¸‚ç›ˆç‡æ•°æ®
â”‚   â”œâ”€â”€ Fundamental_ROE.csv           # å‡€èµ„äº§æ”¶ç›Šç‡æ•°æ®
â”‚   â”œâ”€â”€ Fundamental_Revenue_Growth.csv # è¥æ”¶å¢é•¿ç‡æ•°æ®
â”‚   â”œâ”€â”€ Price_Close.csv               # æ”¶ç›˜ä»·æ•°æ®
â”‚   â”œâ”€â”€ Price_High.csv                # æœ€é«˜ä»·æ•°æ®
â”‚   â”œâ”€â”€ Price_Low.csv                 # æœ€ä½ä»·æ•°æ®
â”‚   â”œâ”€â”€ Price_Open.csv                # å¼€ç›˜ä»·æ•°æ®
â”‚   â”œâ”€â”€ Price_Volume.csv              # æˆäº¤é‡æ•°æ®
â”‚   â”œâ”€â”€ Technical_BB_Width.csv        # å¸ƒæ—å¸¦å®½åº¦
â”‚   â”œâ”€â”€ Technical_MACD.csv            # MACDæŒ‡æ ‡
â”‚   â”œâ”€â”€ Technical_MA_Ratio.csv        # ç§»åŠ¨å¹³å‡æ¯”ç‡
â”‚   â””â”€â”€ Technical_RSI.csv             # RSIæŒ‡æ ‡
â”œâ”€â”€ examples/             # å„ç§æ¡ˆä¾‹æ–‡ä»¶ç›®å½•
â””â”€â”€ datadeal.log           # ç³»ç»Ÿæ—¥å¿—æ–‡ä»¶
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

```bash
# Pythonä¾èµ–
pip install pandas numpy psycopg2-binary python-dotenv

# PostgreSQLæ•°æ®åº“ (ç‰ˆæœ¬ >= 12.0)
```

### æ•°æ®åº“é…ç½®

åˆ›å»º `.env` æ–‡ä»¶æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ï¼š

```bash
# .env æ–‡ä»¶å†…å®¹
DB_HOST=localhost
DB_PORT=5432
DB_NAME=your_database
DB_USER=your_username
DB_PASSWORD=your_password
```

### åŸºç¡€ä½¿ç”¨ç¤ºä¾‹

#### 1. åˆ›å»ºæ•°æ®åº“ç®¡ç†å™¨å®ä¾‹

```python
from postgres_manager import PostgreSQLManager

# ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ˆæ¨èï¼‰
with PostgreSQLManager() as db:
    # æ•°æ®åº“æ“ä½œ
    pass

# æˆ–è€…æ‰‹åŠ¨ç®¡ç†è¿æ¥
db = PostgreSQLManager()
db.connect()
# ... æ“ä½œ
db.close()
```

#### 2. ä»CSVæ–‡ä»¶åˆ›å»ºè¡¨

```python
with PostgreSQLManager() as db:
    # ä»CSVæ–‡ä»¶åˆ›å»ºè¡¨
    success = db.create_table(
        table_name="stock_pb_ratio",
        data_source="sample_data/Fundamental_PB_Ratio.csv",
        overwrite=True  # å¦‚æœè¡¨å­˜åœ¨åˆ™è¦†ç›–
    )
  
    if success:
        print("è¡¨åˆ›å»ºæˆåŠŸ!")
  
        # è·å–è¡¨ä¿¡æ¯
        info = db.get_table_info("stock_pb_ratio")
        print(f"è¡¨ä¿¡æ¯: {info}")
        # è¾“å‡º: {'row_count': 1043, 'column_count': 15, ...}
```

#### 3. ä»DataFrameåˆ›å»ºè¡¨

```python
import pandas as pd
import numpy as np

# åˆ›å»ºç¤ºä¾‹æ•°æ®
dates = pd.date_range('2020-01-01', periods=100, freq='D')
data = pd.DataFrame({
    '000001.SZ': np.random.randn(100),
    '000002.SZ': np.random.randn(100),
    '600000.SH': np.random.randn(100)
}, index=dates)

with PostgreSQLManager() as db:
    success = db.create_table("custom_data", data, overwrite=True)
    if success:
        print("ä»DataFrameåˆ›å»ºè¡¨æˆåŠŸ!")
```

#### 4. ä»å­—å…¸åˆ›å»ºè¡¨

```python
# åˆ›å»ºå­—å…¸æ•°æ®
data_dict = {
    'datetime': ['2020-01-01', '2020-01-02', '2020-01-03'],
    '000001.SZ': [1.23, 1.45, 1.67],
    '000002.SZ': [2.34, 2.56, 2.78],
    '600000.SH': [3.45, 3.67, 3.89]
}

with PostgreSQLManager() as db:
    success = db.create_table("dict_data", data_dict, overwrite=True)
    if success:
        print("ä»å­—å…¸åˆ›å»ºè¡¨æˆåŠŸ!")
```

#### 5. æ•°æ®æŸ¥è¯¢æ“ä½œ

```python
with PostgreSQLManager() as db:
    # åŸºç¡€æŸ¥è¯¢ - è·å–æ‰€æœ‰æ•°æ®
    df_all = db.query_data("stock_pb_ratio")
    print(f"å…¨éƒ¨æ•°æ®å½¢çŠ¶: {df_all.shape}")
  
    # é™åˆ¶æŸ¥è¯¢è¡Œæ•°
    df_limited = db.query_data("stock_pb_ratio", limit=100)
    print(f"é™åˆ¶100è¡Œ: {df_limited.shape}")
  
    # æ—¶é—´åˆ‡ç‰‡æŸ¥è¯¢
    df_slice = db.query_data(
        "stock_pb_ratio",
        start_date='2020-01-01',
        end_date='2020-12-31'
    )
    print(f"2020å¹´æ•°æ®: {df_slice.shape}")
  
    # åˆ—ç­›é€‰æŸ¥è¯¢
    df_columns = db.query_data(
        "stock_pb_ratio",
        columns=['000001.SZ', '000002.SZ', '600000.SH']
    )
    print(f"é€‰å®šåˆ—æ•°æ®: {df_columns.shape}")
  
    # ç»„åˆæŸ¥è¯¢
    df_complex = db.query_data(
        "stock_pb_ratio",
        start_date='2021-01-01',
        end_date='2021-06-30',
        columns=['000001.SZ', '600000.SH'],
        limit=50
    )
    print(f"å¤åˆæŸ¥è¯¢ç»“æœ: {df_complex.shape}")
```

#### 6. æ•°æ®æ’å…¥å’Œæ›´æ–°

```python
# å‡†å¤‡æ–°æ•°æ®
new_dates = pd.date_range('2023-01-01', periods=10, freq='D')
new_data = pd.DataFrame({
    '000001.SZ': np.random.randn(10),
    '000002.SZ': np.random.randn(10),
    '600000.SH': np.random.randn(10)
}, index=new_dates)

with PostgreSQLManager() as db:
    # æ’å…¥æ–°æ•°æ®
    success = db.insert_data("stock_pb_ratio", new_data)
    if success:
        print("æ•°æ®æ’å…¥æˆåŠŸ!")
  
    # æŸ¥è¯¢éªŒè¯
    latest_data = db.query_data(
        "stock_pb_ratio",
        start_date='2023-01-01'
    )
    print(f"æ–°æ’å…¥çš„æ•°æ®: {latest_data.shape}")
```

### é«˜çº§åŠŸèƒ½ä½¿ç”¨

#### 1. æ‰¹é‡æ•°æ®å¯¼å…¥

```python
from advanced_manager import AdvancedPostgreSQLManager

with AdvancedPostgreSQLManager() as db:
    # æ‰¹é‡å¯¼å…¥å¤šä¸ªæ•°æ®æºï¼ˆæ··åˆç±»å‹ï¼‰
    data_sources = [
        "sample_data/Fundamental_PB_Ratio.csv",  # CSVæ–‡ä»¶
        dataframe_pe_ratio,                      # DataFrameå¯¹è±¡
        {"datetime": ["2020-01-01"], "000001.SZ": [1.23]}  # å­—å…¸æ•°æ®
    ]
  
    table_names = ["pb_data", "pe_data", "custom_data"]
  
    results = db.batch_insert_data(data_sources, table_names, overwrite=True)
    print(f"æ‰¹é‡å¯¼å…¥ç»“æœ: {results}")
```

#### 2. å¤šå› å­æŸ¥è¯¢åŠŸèƒ½

```python
with AdvancedPostgreSQLManager() as db:
    # è·¨è¡¨å¤šå› å­æŸ¥è¯¢
    result = db.query_data_multifactor(
        start_date='2020-01-01',
        end_date='2020-12-31',
        codes=['000001.SZ', '000002.SZ', '600000.SH']  # å¯é€‰ï¼šæŒ‡å®šè‚¡ç¥¨ä»£ç 
    )
  
    print(f"å¤šå› å­æ•°æ®å½¢çŠ¶: {result.shape}")
    print(f"åŒ…å«å› å­: {result.columns.tolist()}")
  
    # ç»“æœåŒ…å«æ‰€æœ‰å› å­è¡¨çš„æ•°æ®ï¼ŒæŒ‰æ—¶é—´å’Œè‚¡ç¥¨ä»£ç ç»„ç»‡
    # åˆ—åæ ¼å¼: factor_table_name + '_' + stock_code
```

#### 3. æ‰¹é‡æ–‡ä»¶å¯¼å…¥

```python
with AdvancedPostgreSQLManager() as db:
    # æ‰¹é‡å¯¼å…¥æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰CSVæ–‡ä»¶
    results = db.batch_insert_files(
        file_directory="sample_data/",
        table_prefix="factor_",
        file_pattern="*.csv",
        overwrite=True
    )
  
    print(f"å¯¼å…¥ç»“æœ: {results}")
  
    # æŸ¥è¯¢å¯¼å…¥çš„è¡¨
    tables = db.list_tables()
    factor_tables = [t for t in tables if t.startswith('factor_')]
    print(f"å› å­è¡¨: {factor_tables}")
```

#### 4. æ•°æ®ç»Ÿè®¡åˆ†æ

```python
with AdvancedPostgreSQLManager() as db:
    # è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯
    stats = db.get_data_statistics("stock_pb_ratio")
    print("æ•°æ®ç»Ÿè®¡:")
    print(f"- æ€»è¡Œæ•°: {stats['row_count']}")
    print(f"- æ€»åˆ—æ•°: {stats['column_count']}")
    print(f"- æ—¥æœŸèŒƒå›´: {stats['date_range']}")
    print(f"- ç¼ºå¤±å€¼: {stats['missing_values']}")
  
    # è·å–æ•°æ®è´¨é‡æŠ¥å‘Š
    quality_report = db.validate_data_quality("stock_pb_ratio")
    print(f"æ•°æ®è´¨é‡: {quality_report}")
```

#### 5. æ•°æ®å¯¼å‡º

```python
with AdvancedPostgreSQLManager() as db:
    # å¯¼å‡ºå…¨éƒ¨æ•°æ®
    success = db.export_data(
        "stock_pb_ratio", 
        "exported_data.csv"
    )
  
    # å¯¼å‡ºéƒ¨åˆ†æ•°æ®
    success = db.export_data(
        "stock_pb_ratio",
        "partial_data.csv",
        start_date='2020-01-01',
        end_date='2020-12-31',
        limit=1000
    )
  
    if success:
        print("æ•°æ®å¯¼å‡ºæˆåŠŸ!")
```

#### 6. è¡¨æ ¼ç®¡ç†

```python
with PostgreSQLManager() as db:
    # åˆ—å‡ºæ‰€æœ‰è¡¨
    tables = db.list_tables()
    print(f"æ•°æ®åº“ä¸­çš„è¡¨: {tables}")
  
    # è·å–è¡¨è¯¦ç»†ä¿¡æ¯
    for table in tables:
        info = db.get_table_info(table)
        print(f"{table}: {info}")
  
    # åˆ é™¤è¡¨ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰
    # db.drop_table("old_table_name")
```

## ğŸ“‹ APIæ–‡æ¡£

### PostgreSQLManager ç±»

#### æ ¸å¿ƒæ–¹æ³•

##### `__init__(host=None, port=None, database=None, user=None, password=None)`

åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨

**å‚æ•°**:

- `host` (str, optional): æ•°æ®åº“ä¸»æœºåœ°å€ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–
- `port` (int, optional): æ•°æ®åº“ç«¯å£ï¼Œé»˜è®¤5432
- `database` (str, optional): æ•°æ®åº“åç§°
- `user` (str, optional): ç”¨æˆ·å
- `password` (str, optional): å¯†ç 

##### `create_table(table_name, data_source, overwrite=False)`

åˆ›å»ºæ•°æ®åº“è¡¨

**å‚æ•°**:

- `table_name` (str): è¡¨åç§°
- `data_source` (str|DataFrame|dict): CSVæ–‡ä»¶è·¯å¾„ã€pandas DataFrameæˆ–å­—å…¸æ•°æ®
- `overwrite` (bool): æ˜¯å¦è¦†ç›–å·²å­˜åœ¨çš„è¡¨

**è¿”å›**: `bool` - åˆ›å»ºæ˜¯å¦æˆåŠŸ

**ç¤ºä¾‹**:

```python
# ä»CSVåˆ›å»º
success = db.create_table("my_table", "data.csv", overwrite=True)

# ä»DataFrameåˆ›å»º
success = db.create_table("my_table", dataframe, overwrite=True)

# ä»å­—å…¸åˆ›å»º
data_dict = {'datetime': ['2020-01-01'], 'col1': [1.23]}
success = db.create_table("my_table", data_dict, overwrite=True)
```

##### `insert_data(table_name, data_source, update_existing=False)`

æ’å…¥æ•°æ®

**å‚æ•°**:

- `table_name` (str): è¡¨åç§°
- `data_source` (str|DataFrame|dict): æ•°æ®æºï¼ˆCSVæ–‡ä»¶è·¯å¾„ã€DataFrameæˆ–å­—å…¸ï¼‰
- `update_existing` (bool): æ˜¯å¦æ›´æ–°å·²å­˜åœ¨çš„æ•°æ®

**è¿”å›**: `bool` - æ’å…¥æ˜¯å¦æˆåŠŸ

**ç¤ºä¾‹**:

```python
# æ’å…¥DataFrameæ•°æ®
new_data = pd.DataFrame({...})
success = db.insert_data("my_table", new_data)

# æ’å…¥å­—å…¸æ•°æ®
dict_data = {'datetime': ['2023-01-01'], 'col1': [1.23]}
success = db.insert_data("my_table", dict_data)
```

##### `query_data(table_name, start_date=None, end_date=None, columns=None, limit=None)`

æŸ¥è¯¢æ•°æ®

**å‚æ•°**:

- `table_name` (str): è¡¨åç§°
- `start_date` (str, optional): å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
- `end_date` (str, optional): ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
- `columns` (list, optional): è¦æŸ¥è¯¢çš„åˆ—ååˆ—è¡¨
- `limit` (int, optional): é™åˆ¶è¿”å›è¡Œæ•°

**è¿”å›**: `pandas.DataFrame` - æŸ¥è¯¢ç»“æœ

**ç¤ºä¾‹**:

```python
# æŸ¥è¯¢å…¨éƒ¨æ•°æ®
df = db.query_data("my_table")

# æ—¶é—´åˆ‡ç‰‡æŸ¥è¯¢
df = db.query_data("my_table", start_date='2020-01-01', end_date='2020-12-31')

# åˆ—ç­›é€‰æŸ¥è¯¢
df = db.query_data("my_table", columns=['col1', 'col2'])

# ç»„åˆæŸ¥è¯¢
df = db.query_data("my_table", start_date='2020-01-01', columns=['col1'], limit=100)
```

##### `get_table_info(table_name)`

è·å–è¡¨ä¿¡æ¯

**å‚æ•°**:

- `table_name` (str): è¡¨åç§°

**è¿”å›**: `dict` - è¡¨ä¿¡æ¯å­—å…¸

**ç¤ºä¾‹**:

```python
info = db.get_table_info("my_table")
# è¿”å›: {'row_count': 1000, 'column_count': 10, 'columns': [...]}
```

##### `list_tables()`

åˆ—å‡ºæ‰€æœ‰è¡¨

**è¿”å›**: `list` - è¡¨ååˆ—è¡¨

##### `drop_table(table_name)`

åˆ é™¤è¡¨

**å‚æ•°**:

- `table_name` (str): è¡¨åç§°

**è¿”å›**: `bool` - åˆ é™¤æ˜¯å¦æˆåŠŸ

### AdvancedPostgreSQLManager ç±»

ç»§æ‰¿è‡ª `PostgreSQLManager`ï¼Œæä¾›é¢å¤–çš„é«˜çº§åŠŸèƒ½ã€‚

##### `batch_insert_data(data_sources, table_names, overwrite=False)`

æ‰¹é‡å¯¼å…¥å¤šç§æ•°æ®æº

**å‚æ•°**:

- `data_sources` (list): æ•°æ®æºåˆ—è¡¨ï¼ˆCSVæ–‡ä»¶è·¯å¾„ã€DataFrameæˆ–å­—å…¸ï¼‰
- `table_names` (list): å¯¹åº”çš„è¡¨ååˆ—è¡¨
- `overwrite` (bool): æ˜¯å¦è¦†ç›–å·²å­˜åœ¨çš„è¡¨

**è¿”å›**: `dict` - æ¯ä¸ªæ•°æ®æºçš„å¯¼å…¥ç»“æœ

**ç¤ºä¾‹**:

```python
data_sources = ["file1.csv", dataframe, {"datetime": ["2020-01-01"], "col1": [1.23]}]
table_names = ["table1", "table2", "table3"]
results = db.batch_insert_data(data_sources, table_names, overwrite=True)
```

##### `query_data_multifactor(start_date=None, end_date=None, codes=None)`

å¤šå› å­æŸ¥è¯¢åŠŸèƒ½

**å‚æ•°**:

- `start_date` (str, optional): å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
- `end_date` (str, optional): ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
- `codes` (list, optional): è‚¡ç¥¨ä»£ç åˆ—è¡¨

**è¿”å›**: `pandas.DataFrame` - å¤šå› å­æŸ¥è¯¢ç»“æœ

**ç¤ºä¾‹**:

```python
# æŸ¥è¯¢æ‰€æœ‰å› å­æ•°æ®
df = db.query_data_multifactor(start_date='2020-01-01', end_date='2020-12-31')

# æŸ¥è¯¢æŒ‡å®šè‚¡ç¥¨çš„å› å­æ•°æ®
df = db.query_data_multifactor(codes=['000001.SZ', '600000.SH'])
```

##### `batch_insert_files(file_directory, table_prefix="", file_pattern="*.csv", overwrite=False)`

æ‰¹é‡å¯¼å…¥æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶

**å‚æ•°**:

- `file_directory` (str): æ–‡ä»¶å¤¹è·¯å¾„
- `table_prefix` (str): è¡¨åå‰ç¼€
- `file_pattern` (str): æ–‡ä»¶åŒ¹é…æ¨¡å¼
- `overwrite` (bool): æ˜¯å¦è¦†ç›–å·²å­˜åœ¨çš„è¡¨

**è¿”å›**: `dict` - æ¯ä¸ªæ–‡ä»¶çš„å¯¼å…¥ç»“æœ

##### `get_data_statistics(table_name)`

è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯

**å‚æ•°**:

- `table_name` (str): è¡¨åç§°

**è¿”å›**: `dict` - ç»Ÿè®¡ä¿¡æ¯å­—å…¸

##### `export_data(table_name, output_file, **kwargs)`

å¯¼å‡ºæ•°æ®

**å‚æ•°**:

- `table_name` (str): è¡¨åç§°
- `output_file` (str): è¾“å‡ºæ–‡ä»¶è·¯å¾„
- `**kwargs`: æŸ¥è¯¢å‚æ•°ï¼ˆåŒquery_dataæ–¹æ³•ï¼‰

**è¿”å›**: `bool` - å¯¼å‡ºæ˜¯å¦æˆåŠŸ

##### `validate_data_quality(table_name)`

éªŒè¯æ•°æ®è´¨é‡

**å‚æ•°**:

- `table_name` (str): è¡¨åç§°

**è¿”å›**: `dict` - æ•°æ®è´¨é‡æŠ¥å‘Š

## âš™ï¸ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡é…ç½®

ç³»ç»Ÿæ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡æˆ– `.env` æ–‡ä»¶è¿›è¡Œé…ç½®ï¼š

```bash
# æ•°æ®åº“è¿æ¥é…ç½®
DB_HOST=localhost          # æ•°æ®åº“ä¸»æœº
DB_PORT=5432              # æ•°æ®åº“ç«¯å£
DB_NAME=financial_data    # æ•°æ®åº“åç§°
DB_USER=postgres          # ç”¨æˆ·å
DB_PASSWORD=your_password # å¯†ç 

# æ—¥å¿—é…ç½®
LOG_LEVEL=INFO            # æ—¥å¿—çº§åˆ«: DEBUG, INFO, WARNING, ERROR
LOG_FILE=datadeal.log     # æ—¥å¿—æ–‡ä»¶è·¯å¾„

# æ€§èƒ½é…ç½®
BATCH_SIZE=1000           # æ‰¹é‡æ“ä½œå¤§å°
CONNECTION_TIMEOUT=30     # è¿æ¥è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
```

### æ•°æ®åº“ä¼˜åŒ–é…ç½®

æ¨èçš„PostgreSQLé…ç½®ä¼˜åŒ–ï¼š

```sql
-- é’ˆå¯¹æ—¶é—´åºåˆ—æ•°æ®çš„ä¼˜åŒ–
ALTER SYSTEM SET shared_buffers = '256MB';
ALTER SYSTEM SET effective_cache_size = '1GB';
ALTER SYSTEM SET maintenance_work_mem = '64MB';
ALTER SYSTEM SET checkpoint_completion_target = 0.9;
ALTER SYSTEM SET wal_buffers = '16MB';
ALTER SYSTEM SET default_statistics_target = 100;
```

## ğŸ§ª æµ‹è¯•å’ŒéªŒè¯

### è¿è¡Œæµ‹è¯•

```bash
# åŸºç¡€åŠŸèƒ½æµ‹è¯•
python simple_test.py

# ç»¼åˆåŠŸèƒ½æµ‹è¯•
python comprehensive_test.py

# å®Œæ•´æ¼”ç¤º
python demo_usage.py
```

### æµ‹è¯•è¦†ç›–èŒƒå›´

- âœ… æ•°æ®åº“è¿æ¥æµ‹è¯•
- âœ… è¡¨æ ¼åˆ›å»ºå’Œåˆ é™¤æµ‹è¯•
- âœ… æ•°æ®å¯¼å…¥å’ŒæŸ¥è¯¢æµ‹è¯•
- âœ… æ—¶é—´åˆ‡ç‰‡åŠŸèƒ½æµ‹è¯•
- âœ… æ‰¹é‡æ“ä½œæµ‹è¯•
- âœ… é”™è¯¯å¤„ç†æµ‹è¯•
- âœ… æ€§èƒ½åŸºå‡†æµ‹è¯•

## ğŸ“ˆ æ€§èƒ½ç‰¹æ€§

### æ€§èƒ½æŒ‡æ ‡

- **æ•°æ®å¯¼å…¥é€Ÿåº¦**: 10,000+ è¡Œ/ç§’
- **æŸ¥è¯¢å“åº”æ—¶é—´**: < 100ms (å…¸å‹æŸ¥è¯¢)
- **å†…å­˜ä½¿ç”¨**: ä¼˜åŒ–çš„æ‰¹é‡å¤„ç†ï¼Œå†…å­˜å ç”¨ < 500MB
- **å¹¶å‘æ”¯æŒ**: æ”¯æŒå¤šè¿æ¥å¹¶å‘æ“ä½œ

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **ç´¢å¼•ä¼˜åŒ–**: ç³»ç»Ÿè‡ªåŠ¨ä¸ºdatetimeåˆ—åˆ›å»ºç´¢å¼•
2. **æ‰¹é‡æ“ä½œ**: ä½¿ç”¨æ‰¹é‡æ’å…¥è€Œéé€è¡Œæ’å…¥
3. **åˆ†é¡µæŸ¥è¯¢**: å¯¹å¤§æ•°æ®é›†ä½¿ç”¨limitå‚æ•°
4. **è¿æ¥æ± **: åœ¨é«˜å¹¶å‘åœºæ™¯ä¸‹ä½¿ç”¨è¿æ¥æ± 

## ğŸ“ æ—¥å¿—è®°å½•

### æ—¥å¿—çº§åˆ«

- `DEBUG`: è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
- `INFO`: ä¸€èˆ¬ä¿¡æ¯è®°å½•
- `WARNING`: è­¦å‘Šä¿¡æ¯
- `ERROR`: é”™è¯¯ä¿¡æ¯

### æ—¥å¿—æ ¼å¼

```
2025-01-21 18:15:02 | INFO | æ•°æ®å¼€å§‹å¯¼å…¥è¡¨ stock_data
2025-01-21 18:15:02 | INFO | å½“å‰æ—¶é—´2025-01-21, å¯¼å…¥æ—¶é—´ç‚¹2020-01-01 å› å­PB_Ratio å¯¼å…¥æˆåŠŸ
2025-01-21 18:15:02 | INFO | å½“å‰æ—¶é—´2025-01-21, å¯¼å…¥æ—¶é—´ç‚¹2020-01-02 å› å­PB_Ratio å¯¼å…¥æˆåŠŸ
...
2025-01-21 18:15:05 | INFO | æ•°æ®æˆåŠŸå¯¼å…¥è¡¨ stock_data, å…± 1043 è¡Œ
```

### æŸ¥çœ‹æ—¥å¿—

```python
# æŸ¥çœ‹æœ€æ–°æ—¥å¿—
with open('datadeal.log', 'r', encoding='utf-8') as f:
    print(f.read())
```

## âš ï¸ æ³¨æ„äº‹é¡¹

### æ•°æ®æ ¼å¼è¦æ±‚

1. **æ—¶é—´åˆ—**: å¿…é¡»å‘½åä¸º `datetime`ï¼Œæ ¼å¼ä¸º YYYY-MM-DD
2. **æ•°å€¼åˆ—**: å¿…é¡»ä¸ºæ•°å€¼ç±»å‹ï¼Œæ”¯æŒæ•´æ•°å’Œæµ®ç‚¹æ•°
3. **åˆ—å**: é¿å…ä½¿ç”¨PostgreSQLä¿ç•™å­—ä½œä¸ºåˆ—å
4. **ç¼–ç **: CSVæ–‡ä»¶å»ºè®®ä½¿ç”¨UTF-8ç¼–ç 

### å®‰å…¨æ³¨æ„äº‹é¡¹

1. **æ•°æ®åº“å‡­æ®**: ä¸è¦åœ¨ä»£ç ä¸­ç¡¬ç¼–ç æ•°æ®åº“å¯†ç 
2. **SQLæ³¨å…¥**: ç³»ç»Ÿå·²å†…ç½®SQLæ³¨å…¥é˜²æŠ¤
3. **æƒé™æ§åˆ¶**: ç¡®ä¿æ•°æ®åº“ç”¨æˆ·å…·æœ‰é€‚å½“çš„æƒé™
4. **å¤‡ä»½**: å®šæœŸå¤‡ä»½é‡è¦æ•°æ®

### æ€§èƒ½æ³¨æ„äº‹é¡¹

1. **å¤§æ•°æ®é›†**: å¯¹äºè¶…å¤§æ•°æ®é›†ï¼Œå»ºè®®åˆ†æ‰¹å¤„ç†
2. **å†…å­˜ç®¡ç†**: æŸ¥è¯¢å¤§é‡æ•°æ®æ—¶ä½¿ç”¨limitå‚æ•°
3. **ç´¢å¼•ç»´æŠ¤**: å®šæœŸç»´æŠ¤æ•°æ®åº“ç´¢å¼•
4. **è¿æ¥ç®¡ç†**: ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿è¿æ¥æ­£ç¡®å…³é—­

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. è¿æ¥å¤±è´¥

```
é”™è¯¯: could not connect to server
è§£å†³: æ£€æŸ¥æ•°æ®åº“æœåŠ¡æ˜¯å¦å¯åŠ¨ï¼Œç¡®è®¤è¿æ¥å‚æ•°æ­£ç¡®
```

#### 2. è¡¨å·²å­˜åœ¨

```
é”™è¯¯: relation "table_name" already exists
è§£å†³: ä½¿ç”¨ overwrite=True å‚æ•°æˆ–æ‰‹åŠ¨åˆ é™¤è¡¨
```

#### 3. æ•°æ®ç±»å‹é”™è¯¯

```
é”™è¯¯: invalid input syntax for type double precision
è§£å†³: æ£€æŸ¥CSVæ–‡ä»¶ä¸­çš„æ•°æ®æ ¼å¼ï¼Œç¡®ä¿æ•°å€¼åˆ—ä¸åŒ…å«éæ•°å­—å­—ç¬¦
```

#### 4. å†…å­˜ä¸è¶³

```
é”™è¯¯: out of memory
è§£å†³: ä½¿ç”¨limitå‚æ•°é™åˆ¶æŸ¥è¯¢ç»“æœï¼Œæˆ–å¢åŠ ç³»ç»Ÿå†…å­˜
```

### è°ƒè¯•æ¨¡å¼

å¯ç”¨è¯¦ç»†æ—¥å¿—è®°å½•ï¼š

```python
import logging
logging.basicConfig(level=logging.DEBUG)

with PostgreSQLManager() as db:
    # è¯¦ç»†çš„æ“ä½œæ—¥å¿—å°†è¢«è®°å½•
    pass
```

## ğŸ“š ç‰ˆæœ¬å†å²

### v3.0.0 (2025-01-21) - é•¿è¡¨æ ¼æ ¼å¼é‡æ„

- ğŸ”„ **é‡å¤§æ›´æ–°**: æ•°æ®å­˜å‚¨æ ¼å¼ä»å®½è¡¨æ ¼ï¼ˆdatetime*codeï¼‰æ”¹ä¸ºé•¿è¡¨æ ¼ï¼ˆdatetime, code, metric, valueï¼‰
- ğŸ¯ **è§£å†³é—®é¢˜**: çªç ´PostgreSQL 1600å­—æ®µé™åˆ¶ï¼Œæ”¯æŒå…¨Aè‚¡5000åªè‚¡ç¥¨æ•°æ®
- âœ… **æ ¸å¿ƒä¿®æ”¹**:
  - ä¿®æ”¹ `_load_data` å‡½æ•°ï¼šå°†å®½è¡¨æ ¼æ•°æ®è½¬æ¢ä¸ºé•¿è¡¨æ ¼æ ¼å¼
  - ä¿®æ”¹ `_create_table_from_dataframe` å‡½æ•°ï¼šåˆ›å»ºæ ‡å‡†åŒ–çš„é•¿è¡¨æ ¼ç»“æ„ï¼ˆdatetime, code, metric, valueï¼‰
  - ä¿®æ”¹ `_insert_dataframe` å‡½æ•°ï¼šé€‚é…é•¿è¡¨æ ¼æ•°æ®æ’å…¥ï¼Œä¿æŒæ—¥æœŸæ—¥å¿—æ˜¾ç¤º
  - ä¿®æ”¹ `query_data` å‡½æ•°ï¼šä»é•¿è¡¨æ ¼è¯»å–æ•°æ®åè½¬æ¢ä¸ºå®½è¡¨æ ¼æ ¼å¼è¿”å›
  - ä¿æŒ `query_data_multifactor` å‡½æ•°åŸæœ‰åŠŸèƒ½ï¼Œé€‚é…é•¿è¡¨æ ¼æŸ¥è¯¢
  - ä¿®æ”¹ `advanced_manager.py` ä¸­ç›¸å…³å‡½æ•°ä»¥æ”¯æŒæ–°çš„é•¿è¡¨æ ¼æ ¼å¼
- ğŸš€ **æ€§èƒ½æå‡**: æ”¯æŒæ›´å¤§è§„æ¨¡çš„è‚¡ç¥¨æ•°æ®å­˜å‚¨å’ŒæŸ¥è¯¢
- ğŸ“Š **å…¼å®¹æ€§**: æŸ¥è¯¢æ¥å£ä¿æŒä¸å˜ï¼Œç”¨æˆ·æ— éœ€ä¿®æ”¹ç°æœ‰ä»£ç 

### v2.0.0 (2025-01-21)

- âœ… **æ–°å¢åŠŸèƒ½**: æ”¯æŒpandas DataFrameå’Œå­—å…¸æ•°æ®æº
- âœ… **æ–°å¢åŠŸèƒ½**: å¤šå› å­æŸ¥è¯¢åŠŸèƒ½ï¼Œæ”¯æŒè·¨è¡¨è”åˆæŸ¥è¯¢
- âœ… **æ–°å¢åŠŸèƒ½**: æ‰¹é‡æ•°æ®å¯¼å…¥ï¼Œæ”¯æŒæ··åˆæ•°æ®æºç±»å‹
- âœ… **å¢å¼ºåŠŸèƒ½**: æ”¹è¿›æ•°æ®åŠ è½½æœºåˆ¶ï¼Œæ”¯æŒæ›´å¤šæ•°æ®æ ¼å¼
- âœ… **ä¼˜åŒ–æ€§èƒ½**: æå‡å¤§æ•°æ®é›†å¤„ç†æ•ˆç‡
- âœ… **å®Œå–„æ–‡æ¡£**: æ›´æ–°APIæ–‡æ¡£å’Œä½¿ç”¨ç¤ºä¾‹

### v1.0.0 (2025-01-21)

- âœ… åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- âœ… æ ¸å¿ƒæ•°æ®ç®¡ç†åŠŸèƒ½
- âœ… é«˜çº§åˆ†æåŠŸèƒ½
- âœ… å®Œæ•´çš„æµ‹è¯•å¥—ä»¶
- âœ… è¯¦ç»†çš„æ–‡æ¡£å’Œç¤ºä¾‹

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç å’Œå»ºè®®ï¼

### å¼€å‘ç¯å¢ƒè®¾ç½®

```bash
# å…‹éš†é¡¹ç›®
git clone <repository_url>
cd Datadeal

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# è¿è¡Œæµ‹è¯•
python -m pytest tests/
```

### æäº¤è§„èŒƒ

- ä½¿ç”¨æ¸…æ™°çš„æäº¤ä¿¡æ¯
- æ·»åŠ é€‚å½“çš„æµ‹è¯•ç”¨ä¾‹
- æ›´æ–°ç›¸å…³æ–‡æ¡£
- éµå¾ªä»£ç é£æ ¼è§„èŒƒ

## ğŸ“ æ”¯æŒä¸è”ç³»

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š

- ğŸ“§ Email: cbw_18810739172@163.com
- ğŸ› Issues: [GitHub Issues](https://github.com/your-repo/issues)

---

**PostgreSQLæ•°æ®ç®¡ç†ç³»ç»Ÿ** - è®©é‡‘èæ•°æ®ç®¡ç†å˜å¾—ç®€å•é«˜æ•ˆï¼ ğŸš€
